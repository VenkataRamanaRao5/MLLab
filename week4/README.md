# Lab Exercise: Understanding the Perceptron Logically

**Note:** Functions should not be called directly.

## Objectives

- Understand the working of a perceptron model through logical implementation.
- Implement a perceptron to classify linearly separable data.

---

## Exercise

### 1. Implementing Perceptron from Scratch

Implement a single-layer perceptron using Python (NumPy) with a simple AND gate or OR gate.

- **Steps:**
  - Initialize weights and bias randomly.
  - Use the sigmoid function as the activation function.
  - Update weights using the perceptron learning rule or with guess.
  - Train the perceptron and test.

---

### 2. Visualizing the Decision Boundary

- After training, plot the decision boundary to show how the perceptron separates the classes.
- Use matplotlib for visualization.

---

### 3. Extension

- Implement a perceptron for the XOR gate.
  - Show that a single-layer perceptron fails for XOR.
- Introduce multi-layer perceptrons (MLP) to overcome this limitation.

---
