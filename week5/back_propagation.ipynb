{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69c6a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f25097b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class perceptron_layer:\n",
    "\n",
    "    def __init__(self, no_input, no_output, lr, act_func, act_deriv_given_act):\n",
    "        self.lr = lr\n",
    "        self.params = np.random.rand(no_output, no_input + 1)\n",
    "        self.activation_function = act_func\n",
    "        self.activation_derivative_given_activation = act_deriv_given_act\n",
    "        print(self)\n",
    "        \n",
    "    def evaluate(self, inputs):\n",
    "        #return self.params * inputs.append(1)\n",
    "        inputs = np.append(inputs, [1]).T\n",
    "        self.activations = inputs\n",
    "        output = self.activation_function(np.dot(self.params, inputs))\n",
    "        return output\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.params)\n",
    "    \n",
    "    def training_forward(self, inputs):\n",
    "        inputs = np.append(inputs, [1]).T\n",
    "        self.activations = inputs\n",
    "        self.z = z = np.dot(self.params, inputs)\n",
    "        self.a = output = self.activation_function(z)\n",
    "        return output\n",
    "    \n",
    "    def error_previous_layer(self, delta_l_plus_1):\n",
    "        #δl=((wl+1)Tδl+1)⊙σ′(zl)\n",
    "        inputs = self.activations\n",
    "        first = np.dot(self.params.T, delta_l_plus_1)\n",
    "        delta_l = first * self.activation_derivative_given_activation(inputs)\n",
    "        #∂C/∂wljk=al−1k * δlj\n",
    "        nudge = self.lr * np.outer(delta_l_plus_1, inputs) \n",
    "        self.params += nudge\n",
    "        return delta_l[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38845261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(arr):\n",
    "    return 1 / (1 + np.exp(-arr))        \n",
    "        \n",
    "def sigmoid_derivative_given_sigmoid_x(x):\n",
    "    return (x) * (1 - (x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a5b2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network:\n",
    "    \n",
    "    def __init__(self, lr, dims, \n",
    "                 act_func = sigmoid, \n",
    "                 act_deriv_given_act = sigmoid_derivative_given_sigmoid_x, \n",
    "                 output_act = sigmoid, \n",
    "                 output_deriv = sigmoid_derivative_given_sigmoid_x\n",
    "                 ):\n",
    "        #self.lr = lr\n",
    "        self.layers = []\n",
    "        '''self.activation_function = act_func\n",
    "        self.activation_derivative_given_activation =  act_deriv_given_act \n",
    "        self.output_activation = output_act\n",
    "        self.output_derivative = output_deriv'''\n",
    "        for i in range(len(dims) - 2):\n",
    "            self.layers.append(perceptron_layer(dims[i], dims[i + 1], lr, act_func, act_deriv_given_act))\n",
    "        self.layers.append(perceptron_layer(dims[-2], dims[-1], lr, output_act, output_deriv))\n",
    "        pass\n",
    "        \n",
    "    def evaluate(self, inputs):\n",
    "        activations = inputs\n",
    "        for layer in self.layers:\n",
    "            activations = layer.evaluate(activations)\n",
    "            pass\n",
    "        return activations\n",
    "    \n",
    "    def delta_last_layer(self, expected, predicted):\n",
    "        return (expected - predicted) * sigmoid_derivative_given_sigmoid_x(predicted)\n",
    "    \n",
    "    def cost_function(self, output, predicted):\n",
    "        return output - predicted\n",
    "    \n",
    "    def train_once(self, inputs, expected):\n",
    "        predicted = nn.evaluate(inputs)\n",
    "        cost = delta = self.delta_last_layer(expected, predicted)\n",
    "        for layer in self.layers[::-1]:\n",
    "            delta = layer.error_previous_layer(delta)\n",
    "        return 0.5 * (cost ** 2).sum()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([repr(layer) for layer in self.layers])\n",
    "    \n",
    "    def train(self, epochs = 10000, data = []):\n",
    "        error_rate = []\n",
    "        weight_updation = []\n",
    "        cost = 0\n",
    "        for i in range(epochs):\n",
    "            for ip, op in data:\n",
    "                costx = self.train_once(ip, op)\n",
    "                cost += costx\n",
    "            error_rate.append([i, cost / epochs])\n",
    "            weight_updation.append([i, self.layers[0].params[0][0]])\n",
    "        cost /= epochs\n",
    "        for ip, op in data:\n",
    "            print(ip, nn.evaluate(ip))\n",
    "        print(nn)\n",
    "        print(\"Error =\", cost)\n",
    "        return error_rate, weight_updation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1b76c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.68249437, 0.5138875 , 0.45738364, 0.82189228],\n",
      "       [0.64959951, 0.22397992, 0.27148904, 0.75508619]])\n",
      "array([[0.12000574, 0.08855163, 0.27712974]])\n"
     ]
    }
   ],
   "source": [
    "nn = neural_network(0.9, [3, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d90af0",
   "metadata": {},
   "source": [
    "# 3 input XOR gate is being modelled\n",
    "I shall hard code all the training data for now, since I have it typed out already for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cb6a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[[0, 0, 0], [0]], [[0, 0, 1], [1]], [[0, 1, 0], [1]], [[0, 1, 1], [0]], [[1, 0, 0], [1]], [[1, 0, 1], [0]], [[1, 1, 0], [0]], [[1, 1, 1], [1]]], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a73fa054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] [0.01238177]\n",
      "[0, 0, 1] [0.992088]\n",
      "[0, 1, 0] [0.99210669]\n",
      "[0, 1, 1] [0.00800521]\n",
      "[1, 0, 0] [0.99212681]\n",
      "[1, 0, 1] [0.00802612]\n",
      "[1, 1, 0] [0.00804672]\n",
      "[1, 1, 1] [0.98691206]\n",
      "array([[-10.87651335, -10.87433356, -10.8680778 ,  16.14175602],\n",
      "       [ -1.50904396,  -1.50872706,  -1.50837415,   2.25305729]])\n",
      "array([[ 24.69162854, -41.14854482,   8.16519376]])\n",
      "Error = 4.319666687541849e-08\n"
     ]
    }
   ],
   "source": [
    "first, second = nn.train(10000, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629de83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
